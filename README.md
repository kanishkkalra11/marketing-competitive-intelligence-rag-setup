# ðŸ§  Retrieval-Augmented Generation (RAG) System

A lightweight, local **Retrieval-Augmented Generation (RAG)** backend built with **Python FastAPI**, **Sentence-Transformers**, and **FAISS**.  
This service ingests PDFs or text documents, embeds them into a vector store, and exposes REST endpoints for semantic retrieval â€” perfect for connecting to LLM agents, n8n, or frontend apps.

---

## ðŸš€ Features

- **Document ingestion & parsing** for `.pdf`, `.txt`, `.md`
- **Multi-stage extraction** (PyPDF â†’ PyMuPDF â†’ PDFMiner fallback)
- **Semantic embeddings** using `all-MiniLM-L6-v2`
- **Vector store** powered by FAISS (cosine similarity search)
- **REST API** endpoints for ingestion, querying, health checks, and reset
- **Secure** with Bearer token authentication and CORS control
- **Expose easily via ngrok** for external workflows or tools

---

## ðŸ§© Architecture Overview

```plaintext
Raw Docs (.pdf/.txt)
        â†“
Parsing & Chunking (~800 words, 120 overlap)
        â†“
Embedding (SentenceTransformers MiniLM-L6-v2)
        â†“
FAISS Vector Store (IndexFlatIP)
        â†“
FastAPI Service (/ingest, /query, /health, /reset)
        â†“
ngrok Tunnel â†’ external tools (n8n, Lovable, etc.)
```

---

## ðŸ“¦ Installation

#### 1. Clone the repository
